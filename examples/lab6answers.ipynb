{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Assignment 6: Creating and Connecting to Databases\n",
    "## DS 6001: Practice and Application of Data Science\n",
    "\n",
    "### Instructions\n",
    "Please answer the following questions as completely as possible using text, code, and the results of code as needed. Format your answers in a Jupyter notebook. To receive full credit, make sure you address every part of the problem, and make sure your document is formatted in a clean and professional way.\n",
    "\n",
    "**Please note: you will not be able to use Rivanna for this lab as Rivanna is not set up to work with Docker or with Databases. If you need help getting your local system running, please let me know.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 0\n",
    "Databases require a lot of external software. The good news is that there are excellent free and open source options to do very advanced work with databases. The bad news is that each piece of additional software comes with its own complications. This problem will guide you through the installation steps for the software you need to run database systems on your computer, document those databases, and connect to them through Python with (fingers crossed) as few problems as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part a\n",
    "Use `pip` to install the following Python packages on your system:\n",
    "```\n",
    "mysql-connector-python\n",
    "psycopg\n",
    "pymongo\n",
    "sqlalchemy\n",
    "wget\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part b\n",
    "With the exception of SQlite, database systems run as external software that must be installed and run on your computer. To make the installation steps easier, you will need some configuration files that I wrote and saved in a GitHub repository. Open your terminal and use the `cd` command to navigate to the folder in your computer where you want to work. Then type\n",
    "```\n",
    "git clone https://github.com/jkropko/ds6001databases\n",
    "```\n",
    "If this command works, it will create a new directory within your current folder called \"ds6001databases\".\n",
    "\n",
    "* Check that this folder exists and contains the following files: LICENSE, README.md, compose.yaml, db_tests.ipynb, and requirements.txt\n",
    "* Save the notebook file you will be using for your Lab 6 work inside the \"ds6001databases\" folder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part c\n",
    "We will be using a system called Docker to work with databases. Docker is the most commonly used platform for working with **containers**. While we will not be delving into the topic of containerization in this course, a container is space in your computer's memory that is set apart from the rest of your computer. We can act as if the container is an entirely new computer, and inside the container we can change the operating system and install other software external to Python, such as database management systems. We can use a container to run Windows on a Mac, or vice versa, or Linux on any system. By far the easiest way to run MySQL, PostgreSQL, and MongoDB is through Docker containers. \n",
    "\n",
    "You will need to install Docker Desktop on your computer. Go to https://www.docker.com/products/docker-desktop/ and click on the Download button, making sure the operating system listed matches the operating system of your computer.\n",
    "\n",
    "Once Docker Desktop is installed, find the Docker Desktop program on your computer and run it.\n",
    "\n",
    "To confirm that Docker Desktop is running, open a terminal and type `docker help`. If you see documentation that begins\n",
    "```\n",
    "Usage:  docker [OPTIONS] COMMAND\n",
    "\n",
    "A self-sufficient runtime for containers\n",
    "```\n",
    "then you are all set. If you see an error that Docker is not found, then the Docker Desktop client was not installed properly, so you should try downloading and installing it from the website again. If you receive a message that the Docker daemon is not running, then Docker is installed but is not running. Find the Docker Desktop executable on your computer and click it to get Docker running."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part d\n",
    "Inside your \"ds6001databases\" folder, create a .env file. On a Mac, type `touch .env` then `open .env` to create and open the file. On Windows, open a new file on Notepad and go to \"Save As\", then save it in your \"ds6001databases\" folder -- make sure to set \"File As Type\" to \"All files\" and name the file \".env\".\n",
    "\n",
    "Inside the .env file you need to choose passwords for the MySQL, PostgreSQL, and MongoDB databases, so type\n",
    "```\n",
    "MYSQL_ROOT_PASSWORD=redlobstercheddarbiscuits\n",
    "POSTGRES_PASSWORD=outbackbloominonion\n",
    "MONGO_INITDB_ROOT_PASSWORD=olivegardenunlimitedbreadsticks\n",
    "MONGO_INITDB_ROOT_USERNAME=mongo\n",
    "mongo_init_db = mongodb\n",
    "MYSQL_DATABASE=mysql\n",
    "```\n",
    "Change the passwords on the first three lines to whatever you want, but DON'T USE THE @ SYMBOL as that will cause problems. Leave the fourth, fifth, and sixth lines alone, as well as the names of each environmental variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part e\n",
    "In the terminal, make sure you are in the \"ds6001databases\" folder (you can check by typing `pwd`. If not, then use `cd` to navigate to the \"ds6001databases\" folder). Then type\n",
    "```\n",
    "docker compose up\n",
    "```\n",
    "This command launches all of the databases. If successful, you will see a long stream of output with messages that begin `ds6001databases-postgres-1`, `ds6001databases-mysql-1`, and `ds6001databases-mongo-1`. If not, we will need to debug together, but the issue likely has to do with something preventing parts a, b, c, or d from being completed successfully."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part f\n",
    "To confirm that the databases are running on your system, open the \"db_tests.ipynb\" notebook file, which should be saved in you \"ds6001databases\" folder. Run everything in this notebook and make sure there are no errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part g\n",
    "In addition to the databases, we will be using dbdocs.io to create documentation for our databases and post them online with a stable URL. But to get dbdocs running, you first need to install NodeJS on your computer: https://nodejs.org/en\n",
    "\n",
    "Then to install dbdocs, follow the instructions here: https://dbdocs.io/docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part h\n",
    "Finally, create a notebook inside your \"ds6001databases\" folder for your work on this lab. Import the following libraries, and load the `.env` file where you store your passwords. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wget\n",
    "import sqlite3\n",
    "import sqlalchemy\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "POSTGRES_PASSWORD = os.getenv('POSTGRES_PASSWORD')\n",
    "MONGO_INITDB_ROOT_USERNAME = os.getenv('MONGO_INITDB_ROOT_USERNAME')\n",
    "MONGO_INITDB_ROOT_PASSWORD = os.getenv('MONGO_INITDB_ROOT_PASSWORD')\n",
    "mongo_init_db = os.getenv('mongo_init_db')\n",
    "MYSQL_ROOT_PASSWORD = os.getenv('MYSQL_ROOT_PASSWORD')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1 \n",
    "**This problem requires you to create Markdown tables** \n",
    "\n",
    "To create a table in a markdown cell, I recommend using the markdown table generator here: https://www.tablesgenerator.com/markdown_tables. This interface allows you to choose the number of rows and columns, fill in those rows and colums, and push the \"generate\" button. The website will display markdown table code that looks like:\n",
    "```\n",
    "| Day       | Temp | Rain |\n",
    "|-----------|------|------|\n",
    "| Monday    | 74   | No   |\n",
    "| Tuesday   | 58   | Yes  |\n",
    "| Wednesday | 76   | No   |\n",
    "```\n",
    "Copy the markdown code and paste it into a markdown cell in your notebook. Markdown will read the code and display a table that looks like this:\n",
    "\n",
    "| Day       | Temp | Rain |\n",
    "|-----------|------|------|\n",
    "| Monday    | 74   | No   |\n",
    "| Tuesday   | 58   | Yes  |\n",
    "| Wednesday | 76   | No   |\n",
    "\n",
    "Suppose that we have (fake) data on people who were hospitalized and received at least one prescription for a medication. Here are ten records in the data:\n",
    "\n",
    "(If this table gets cut off in the PDF, please look at the .ipynb notebook file on the module 6 page on Canvas)\n",
    "\n",
    "| patient_name       | date_of_birth | prescribed_drug | prior_conditions                     | patient_sex | patient_insurance      | drug_maker               | drug_cost | attending_physician | AP_medschool                      | AP_years_experience | hospital                       | hospital_location |\n",
    "|--------------------|---------------|-----------------|--------------------------------------|-------------|------------------------|--------------------------|-----------|---------------------|-----------------------------------|--------------------|--------------------------------|-------------------|\n",
    "| Nkemdilim Arendonk | 2/21/1962     | Amoxil          | [Pneumonia, Diabetes]                | M           | Aetna                  | USAntibiotics            | 14.62     | Earnest Caro        | University of California (Irvine) | 14                 | UPMC Presbyterian Shadyside    | Pittsburgh, PA    |\n",
    "| Nkemdilim Arendonk | 2/21/1962     | Micronase       | [Pneumonia, Diabetes]                | M           | Aetna                  | Pfizer                   | 20.55     | Earnest Caro        | University of California (Irvine) | 14                 | UPMC Presbyterian Shadyside    | Pittsburgh, PA    |\n",
    "| Raniero Coumans    | 8/15/1990     | Zosyn           | [Appendicitis, Crohn's disease]      | M           | Cigna                  | Baxter International Inc | 394.00    | Pamela English      | University of Michigan            | 29                 | Northwestern Memorial Hospital | Chicago, IL       |\n",
    "| Raniero Coumans    | 8/15/1990     | Humira          | [Appendicitis, Crohn's disease]      | M           | Cigna                  | Abbvie                   | 7000.00   | Pamela English      | University of Michigan            | 29                 | Northwestern Memorial Hospital | Chicago, IL       |\n",
    "| Mizuki Debenham    | 3/12/1977     | Inlyta          | [Kidney Cancer]                      | F           | Kaiser Permanente      | Pfizer                   | 21644.00  | Lewis Conti         | North Carolina State University   | 8                  | Houston Methodist Hospital     | Houston, TX       |\n",
    "| Zoë De Witt        | 11/23/1947    | Atenolol        | [Cardiomyopathy, Diabetes, Sciatica] | F           | Medicare               | Mylan Pharmaceuticals    | 10.58     | Theresa Dahlmans    | Lake Erie College of Medicine     | 17                 | Mount Sinai Hospital           | New York, NY      |\n",
    "| Zoë De Witt        | 11/23/1947    | Micronase       | [Cardiomyopathy, Diabetes, Sciatica] | F           | Medicare               | Pfizer                   | 20.55     | Theresa Dahlmans    | Lake Erie College of Medicine     | 17                 | Mount Sinai Hospital           | New York, NY      |\n",
    "| Zoë De Witt        | 11/23/1947    | Demerol         | [Cardiomyopathy, Diabetes, Sciatica] | F           | Medicare               | Pfizer                   | 37.50     | Theresa Dahlmans    | Lake Erie College of Medicine     | 17                 | Mount Sinai Hospital           | New York, NY      |\n",
    "| Bonnie Hooper      | 7/4/1951      | Xeloda          | [Pancreatic Cancer, Sciatica]        | F           | Blue Cross Blue Shield | Genentech                | 860.00    | Steven Garbutt      | Ohio State University             | 36                 | UCSF Medical Center            | San Francisco, CA |\n",
    "| Bonnie Hooper      | 7/4/1951      | Demerol         | [Pancreatic Cancer, Sciatica]        | F           | Blue Cross Blue Shield | Pfizer                   | 37.50     | Steven Garbutt      | Ohio State University             | 36                 | UCSF Medical Center            | San Francisco, CA |\n",
    "\n",
    "The columns in this dataset are:\n",
    "\n",
    "* **patient_name**: The patient's name\n",
    "* **date_of_birth**: The patient's date of birth\n",
    "* **prescribed_drug**: The brand name of the medication that patient has been prescribed\n",
    "* **prior_conditions**: A list of the conditions that the patient had been diagnosed with prior to the patient's hospitalization\n",
    "* **patient_sex**: The patient's sex\n",
    "* **patient_insurance**: The company responsible for the patient's health insurance coverage\n",
    "* **drug_maker**: The company that manufactures the prescribed drug\n",
    "* **drug_cost**: The cost of the prescribed drug\n",
    "* **attending_physician**: The name of the attending physician for the patient\n",
    "* **AP_medschool**: The name of the school where the attending physician got a medical degree\n",
    "* **AP_years_experience**: The attending physician's number of years of experience post-residency\n",
    "* **hospital**: The hospital where the attending physicial is employed\n",
    "* **hospital_location**: The location of the hospital\n",
    "\n",
    "For this problem, assume that \n",
    "\n",
    "1. No two rows in this table share both the same patient and the same prescribed drug.\n",
    "   \n",
    "2. Some patients in the data share the same name, but no two patients in the data share the same name and date of birth.\n",
    "\n",
    "3. No two different drugs share the same brand name.\n",
    "\n",
    "4. No two attending physicians have the same name, and every attending physician is employed at only one hospital.\n",
    "\n",
    "5. No two hospitals share the same name, and every hospital exists at only one location.\n",
    "   \n",
    "6. Each patient has only one attending physician. (In real-world applications we may want to design a database that allows for multiple hospitalizations for some patients, but here we'll keep it simpler by assuming each patient has one hospitalization with one attending physician.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part a \n",
    "Rearrange the data into a group of data tables that together meet the requirements of first normal form. [2 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rules for 1NF are\n",
    "\n",
    "1. Every table must have a primary key or superkey.\n",
    "\n",
    "2. Every column must be atomic.\n",
    "\n",
    "3. There are no repeating groups.\n",
    "\n",
    "Let's consider rule 2 first. There is a column that contains non-atomic datapoints: the cells for prior_condition contain lists. So we need to break the data up to store each of these conditions separately. \n",
    "\n",
    "However, that's where we run in to a problem with rule 3. Breaking condition into separate columns would require arbitrarily adding ordering language to these column names: *condition1*, *condition2*, *condition3*. In addition we would be generating missing values as not every patient has a second condition, and only one has a third condition.\n",
    "\n",
    "We start by generating a table that lists the different conditions on separate rows and matches each condition to the patient that is hospitalized for that condition. I put both the patient's name and date of birth in the data as these two columns uniquely identify patients. I call this table DIAGNOSES:\n",
    "\n",
    "$$DIAGNOSES$$\n",
    "\n",
    "|patient_name|date_of_birth|prior_condition|\n",
    "|-|-|-|\n",
    "|Nkemdilim Arendonk|2/21/1962|Pneumonia|\n",
    "|Nkemdilim Arendonk|2/21/1962|Diabetes|\n",
    "|Raniero Coumans|8/15/1990|Appendicitis|\n",
    "|Raniero Coumans|8/15/1990|Crohn's disease|\n",
    "|Mizuki Debenham|3/12/1977|Kidney Cancer|\n",
    "|Zoë De Witt|11/23/1947|Cardiomyopathy|\n",
    "|Zoë De Witt|11/23/1947|Diabetes|\n",
    "|Zoë De Witt|11/23/1947|Sciatica|\n",
    "|Bonnie Hooper|7/4/1951|Pancreatic Cancer|\n",
    "|Bonnie Hooper|7/4/1951|Sciatica|\n",
    "\n",
    "I then remove the conditions column from the original dataframe and I call this table PRESCRIPTIONS:\n",
    "\n",
    "$$PRESCRIPTIONS$$\n",
    "\n",
    "| patient_name       | date_of_birth | prescribed_drug | patient_sex | patient_insurance      | drug_maker               | drug_cost | attending_physician | AP_medschool                      | AP_years_experience | hospital                       | hospital_location |\n",
    "|--------------------|---------------|--------------------------------------|-------------|------------------------|--------------------------|-----------|---------------------|-----------------------------------|--------------------|--------------------------------|-------------------|\n",
    "| Nkemdilim Arendonk | 2/21/1962     | Amoxil          |  M           | Aetna                  | USAntibiotics            | 14.62     | Earnest Caro        | University of California (Irvine) | 14                 | UPMC Presbyterian Shadyside    | Pittsburgh, PA    |\n",
    "| Nkemdilim Arendonk | 2/21/1962     | Micronase       |  M           | Aetna                  | Pfizer                   | 20.55     | Earnest Caro        | University of California (Irvine) | 14                 | UPMC Presbyterian Shadyside    | Pittsburgh, PA    |\n",
    "| Raniero Coumans    | 8/15/1990     | Zosyn           |  M           | Cigna                  | Baxter International Inc | 394.00    | Pamela English      | University of Michigan            | 29                 | Northwestern Memorial Hospital | Chicago, IL       |\n",
    "| Raniero Coumans    | 8/15/1990     | Humira          |  M           | Cigna                  | Abbvie                   | 7000.00   | Pamela English      | University of Michigan            | 29                 | Northwestern Memorial Hospital | Chicago, IL       |\n",
    "| Mizuki Debenham    | 3/12/1977     | Inlyta          |  F           | Kaiser Permanente      | Pfizer                   | 21644.00  | Lewis Conti         | North Carolina State University   | 8                  | Houston Methodist Hospital     | Houston, TX       |\n",
    "| Zoë De Witt        | 11/23/1947    | Atenolol        | F           | Medicare               | Mylan Pharmaceuticals    | 10.58     | Theresa Dahlmans    | Lake Erie College of Medicine     | 17                 | Mount Sinai Hospital           | New York, NY      |\n",
    "| Zoë De Witt        | 11/23/1947    | Micronase       |  F           | Medicare               | Pfizer                   | 20.55     | Theresa Dahlmans    | Lake Erie College of Medicine     | 17                 | Mount Sinai Hospital           | New York, NY      |\n",
    "| Zoë De Witt        | 11/23/1947    | Demerol         |  F           | Medicare               | Pfizer                   | 37.50     | Theresa Dahlmans    | Lake Erie College of Medicine     | 17                 | Mount Sinai Hospital           | New York, NY      |\n",
    "| Bonnie Hooper      | 7/4/1951      | Xeloda          |  F           | Blue Cross Blue Shield | Genentech                | 860.00    | Steven Garbutt      | Ohio State University             | 36                 | UCSF Medical Center            | San Francisco, CA |\n",
    "| Bonnie Hooper      | 7/4/1951      | Demerol         |  F           | Blue Cross Blue Shield | Pfizer                   | 37.50     | Steven Garbutt      | Ohio State University             | 36                 | UCSF Medical Center            | San Francisco, CA |\n",
    "\n",
    "The data are now in 1NF. Each table has a primary key: for PRESCRIPTIONS the rows are uniquely identified by the superkey containing patient_name, date_of_birth, and prescribed_drug and for DIAGNOSES the rows are uniquely identified by patient_name, date_of_birth, and prior_condition. There are no longer any non-atomic columns in either table, and there are no repeating groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part b \n",
    "Rearrange the data on the five patients into a group of data tables that together meet the requirements of second normal form. [2 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rules for 2NF are\n",
    "\n",
    "1. The data must already be in 1NF, and\n",
    "\n",
    "2. Every non-prime attribute must depend on the entire primary key.\n",
    "\n",
    "Non-prime attributes are columns that are not part of the primary key. DIAGNOSES already meets these rules because all three columns comprise the primary key in this table, so there are no non-prime attributes that can violate 2NF. But in PRESCRIPTIONS, the primary key consists of patient_name, date_of_birth, and prescribed_drug, so the non-prime attributes are patient_sex, patient_insurance, drug_maker, drug_cost, attending_physician, AP_medschool, AP_years_experience, hospital, and hospital_location.\n",
    "\n",
    "The second rule for 2NF says that all of the non-prime attributes must depend on all of patient_name, date_of_birth, and prescribed_drug. That's not true because\n",
    "\n",
    "* **patient_sex**: depends on the patient, but not the prescription\n",
    "* **patient_insurance**: depends on the patient, but not the prescription\n",
    "* **drug_maker**: depends on the prescription, but not the patient\n",
    "* **drug_cost**: depends on the prescription, but not the patient\n",
    "* **attending_physician**: depends on the patient, but not the prescription\n",
    "* **AP_medschool**: depends on the patient, but not the prescription\n",
    "* **AP_years_experience**: depends on the patient, but not the prescription\n",
    "* **hospital**: depends on the patient, but not the prescription\n",
    "* **hospital_location**: depends on the patient, but not the prescription\n",
    "\n",
    "There are two ways to fix this problem. We can create a new column in the PRESCRIPTIONS table that is a single numeric ID for every patient/prescription combination. Then all of the other attributes depend on this ID, which is now the entire primary key:\n",
    "\n",
    "$$PRESCRIPTIONS$$\n",
    "\n",
    "| patient_prescrip_ID | patient_name       | date_of_birth | prescribed_drug | patient_sex | patient_insurance      | drug_maker               | drug_cost | attending_physician | AP_medschool                      | AP_years_experiece | hospital                       | hospital_location |\n",
    "|---------------------|--------------------|---------------|-----------------|-------------|------------------------|--------------------------|-----------|---------------------|-----------------------------------|--------------------|--------------------------------|-------------------|\n",
    "| 1                   | Nkemdilim Arendonk | 2/21/1962     | Amoxil          | M           | Aetna                  | USAntibiotics            | 14.62     | Earnest Caro        | University of California (Irvine) | 14                 | UPMC Presbyterian Shadyside    | Pittsburgh, PA    |\n",
    "| 2                   | Nkemdilim Arendonk | 2/21/1962     | Micronase       | M           | Aetna                  | Pfizer                   | 20.55     | Earnest Caro        | University of California (Irvine) | 14                 | UPMC Presbyterian Shadyside    | Pittsburgh, PA    |\n",
    "| 3                   | Raniero Coumans    | 8/15/1990     | Zosyn           | M           | Cigna                  | Baxter International Inc | 394.00    | Pamela English      | University of Michigan            | 29                 | Northwestern Memorial Hospital | Chicago, IL       |\n",
    "| 4                   | Raniero Coumans    | 8/15/1990     | Humira          | M           | Cigna                  | Abbvie                   | 7000.00   | Pamela English      | University of Michigan            | 29                 | Northwestern Memorial Hospital | Chicago, IL       |\n",
    "| 5                   | Mizuki Debenham    | 3/12/1977     | Inlyta          | F           | Kaiser Permanente      | Pfizer                   | 21644.00  | Lewis Conti         | North Carolina State University   | 8                  | Houston Methodist Hospital     | Houston, TX       |\n",
    "| 6                   | Zoë De Witt        | 11/23/1947    | Atenolol        | F           | Medicare               | Mylan Pharmaceuticals    | 10.58     | Theresa Dahlmans    | Lake Erie College of Medicine     | 17                 | Mount Sinai Hospital           | New York, NY      |\n",
    "| 7                   | Zoë De Witt        | 11/23/1947    | Micronase       | F           | Medicare               | Pfizer                   | 20.55     | Theresa Dahlmans    | Lake Erie College of Medicine     | 17                 | Mount Sinai Hospital           | New York, NY      |\n",
    "| 8                   | Zoë De Witt        | 11/23/1947    | Demerol         | F           | Medicare               | Pfizer                   | 37.50     | Theresa Dahlmans    | Lake Erie College of Medicine     | 17                 | Mount Sinai Hospital           | New York, NY      |\n",
    "| 9                   | Bonnie Hooper      | 7/4/1951      | Xeloda          | F           | Blue Cross Blue Shield | Genentech                | 860.00    | Steven Garbutt      | Ohio State University             | 36                 | UCSF Medical Center            | San Francisco, CA |\n",
    "| 10                  | Bonnie Hooper      | 7/4/1951      | Demerol         | F           | Blue Cross Blue Shield | Pfizer                   | 37.50     | Steven Garbutt      | Ohio State University             | 36                 | UCSF Medical Center            | San Francisco, CA |\n",
    "\n",
    "This new table technically meets the requirements of 2NF because there is only one column in the primary key, so it is impossible for any other column to depend on only part of this key. But, as we'll see in the next part of this problem, creating this ID results in a lot more work to achieve 3rd normal form. (Note to TA: answers that take this approach receive full credit, but be on the lookout for mistakes getting to 3NF. Regardless of the approach here, everyone should end up in the same place for 3NF)\n",
    "\n",
    "Instead, we can create a better 2NF table by creating new tables. The best approach is to create one new table for each subset of the prime attributes that has non-prime dependent attributes. Here, we can create a PATIENTS table that patient_name, date_of_birth, and the columns that depend on patient alone, and we can create a DRUGS table that contains prescribed_drug and the columns that depend on the drug alone. We then remove these columns from the PRESCRIPTIONS table.\n",
    "\n",
    "The new PATIENTS entity is\n",
    "\n",
    "$$PATIENTS$$\n",
    "\n",
    "| patient_name       | date_of_birth | patient_sex | patient_insurance      | attending_physician | AP_medschool                      | AP_years_experiece | hospital                       | hospital_location |\n",
    "|--------------------|---------------|-------------|------------------------|---------------------|-----------------------------------|--------------------|--------------------------------|-------------------|\n",
    "| Nkemdilim Arendonk | 2/21/1962     | M           | Aetna                  | Earnest Caro        | University of California (Irvine) | 14                 | UPMC Presbyterian Shadyside    | Pittsburgh, PA    |\n",
    "| Raniero Coumans    | 8/15/1990     | M           | Cigna                  | Pamela English      | University of Michigan            | 29                 | Northwestern Memorial Hospital | Chicago, IL       |\n",
    "| Mizuki Debenham    | 3/12/1977     | F           | Kaiser Permanente      | Lewis Conti         | North Carolina State University   | 8                  | Houston Methodist Hospital     | Houston, TX       |\n",
    "| Zoë De Witt        | 11/23/1947    | F           | Medicare               | Theresa Dahlmans    | Lake Erie College of Medicine     | 17                 | Mount Sinai Hospital           | New York, NY      |\n",
    "| Bonnie Hooper      | 7/4/1951      | F           | Blue Cross Blue Shield | Steven Garbutt      | Ohio State University             | 36                 | UCSF Medical Center            | San Francisco, CA |\n",
    "\n",
    "The new DRUGS entity is\n",
    "\n",
    "$$DRUGS$$\n",
    "\n",
    "| prescribed_drug | drug_maker               | drug_cost |\n",
    "|-----------------|--------------------------|-----------|\n",
    "| Amoxil          | USAntibiotics            | 14.62     |\n",
    "| Micronase       | Pfizer                   | 20.55     |\n",
    "| Zosyn           | Baxter International Inc | 394.00    |\n",
    "| Humira          | Abbvie                   | 7000.00   |\n",
    "| Inlyta          | Pfizer                   | 21644.00  |\n",
    "| Atenolol        | Mylan Pharmaceuticals    | 10.58     |\n",
    "| Demerol         | Pfizer                   | 37.50     |\n",
    "| Xeloda          | Genentech                | 860.00    |\n",
    "\n",
    "After removing the non-prime attributes that violated 2NF, the PRESCRIPTIONS table is\n",
    "\n",
    "$$PRESCRIPTIONS$$\n",
    "\n",
    "| patient_name       | date_of_birth | prescribed_drug |\n",
    "|--------------------|---------------|-----------------|\n",
    "| Nkemdilim Arendonk | 2/21/1962     | Amoxil          |\n",
    "| Nkemdilim Arendonk | 2/21/1962     | Micronase       |\n",
    "| Raniero Coumans    | 8/15/1990     | Zosyn           |\n",
    "| Raniero Coumans    | 8/15/1990     | Humira          |\n",
    "| Mizuki Debenham    | 3/12/1977     | Inlyta          |\n",
    "| Zoë De Witt        | 11/23/1947    | Atenolol        |\n",
    "| Zoë De Witt        | 11/23/1947    | Micronase       |\n",
    "| Zoë De Witt        | 11/23/1947    | Demerol         |\n",
    "| Bonnie Hooper      | 7/4/1951      | Xeloda          |\n",
    "| Bonnie Hooper      | 7/4/1951      | Demerol         |\n",
    "\n",
    "And the DIAGNOSES table remains\n",
    "\n",
    "$$DIAGNOSES$$\n",
    "\n",
    "|patient_name|date_of_birth|prior_condition|\n",
    "|-|-|-|\n",
    "|Nkemdilim Arendonk|2/21/1962|Pneumonia|\n",
    "|Nkemdilim Arendonk|2/21/1962|Diabetes|\n",
    "|Raniero Coumans|8/15/1990|Appendicitis|\n",
    "|Raniero Coumans|8/15/1990|Crohn's disease|\n",
    "|Mizuki Debenham|3/12/1977|Kidney Cancer|\n",
    "|Zoë De Witt|11/23/1947|Cardiomyopathy|\n",
    "|Zoë De Witt|11/23/1947|Diabetes|\n",
    "|Zoë De Witt|11/23/1947|Sciatica|\n",
    "|Bonnie Hooper|7/4/1951|Pancreatic Cancer|\n",
    "|Bonnie Hooper|7/4/1951|Sciatica|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part c \n",
    "Rearrange the data into a group of data tables that together meet the requirements of third normal form. [2 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rules for 3NF are\n",
    "\n",
    "1. The data must be in 2NF, and\n",
    "\n",
    "2. there must not be any transitive dependencies.\n",
    "\n",
    "A transitive dependency exists when a non-prime attribute (a column that's not part of the primary key) depends on another non-prime attribute. The best approach to designing a database that meets the requirements of 3NF is to identify all transistive dependencies, create a new table for every column that has at least one other column transitively depending on it, and move all transitively dependent columns to these new tables.\n",
    "\n",
    "We have many non-prime attributes in the PATIENTS entity:\n",
    "\n",
    "* The attending physician's medical school and years of experience depend on the attending physician. Hospital also depends on attending physician as each attending physician works at only one hospital.\n",
    "\n",
    "* The hospital location depends on the hospital.\n",
    "\n",
    "To create a 3NF version of the data, we create two new tables: PHYSICIANS and HOSPITALS. The PHYSICIANS entity is\n",
    "\n",
    "$$PHYSICIANS$$\n",
    "\n",
    "|attending_physician|AP_medschool|AP_years_experiece|hospital|\n",
    "|-|-|-|-|\n",
    "|Earnest Caro|University of California (Irvine)|14|UPMC Presbyterian Shadyside|\n",
    "|Pamela English|University of Michigan|29|Northwestern Memorial Hospital|\n",
    "|Lewis Conti|North Carolina State University|8|Houston Methodist Hospital|\n",
    "|Theresa Dahlmans|Lake Erie College of Medicine|17|Mount Sinai Hospital|\n",
    "|Steven Garbutt|Ohio State University|36|UCSF Medical Center|\n",
    "\n",
    "\n",
    "The HOSPITALS entity is\n",
    "\n",
    "$$HOSPITALS$$\n",
    "\n",
    "|hospital|hospital_location|\n",
    "|-|-|\n",
    "|UPMC Presbyterian Shadyside|Pittsburgh, PA|\n",
    "|Northwestern Memorial Hospital|Chicago, IL|\n",
    "|Houston Methodist Hospital|Houston, TX|\n",
    "|Mount Sinai Hospital|New York, NY|\n",
    "|UCSF Medical Center|San Francisco, CA|\n",
    "\n",
    "\n",
    "And the PATIENTS table is now \n",
    "\n",
    "$$PATIENTS$$\n",
    "\n",
    "|patient_name|date_of_birth|patient_sex|patient_insurance|attending_physician|\n",
    "|-|-|-|-|-|\n",
    "|Nkemdilim Arendonk|2/21/1962|M|Aetna|Earnest Caro|\n",
    "|Raniero Coumans|8/15/1990|M|Cigna|Pamela English|\n",
    "|Mizuki Debenham|3/12/1977|F|Kaiser Permanente|Lewis Conti|\n",
    "|Zoë De Witt|11/23/1947|F|Medicare|Theresa Dahlmans|\n",
    "|Bonnie Hooper|7/4/1951|F|Blue Cross Blue Shield|Steven Garbutt|\n",
    "\n",
    "Together, PRESCRIPTIONS, PATIENTS, DIAGNOSES, DRUGS, PHYSICIANS, and HOSPITALS comprise a relational database in 3NF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2\n",
    "For this problem, create ER diagrams of the database you created in problem 1, part c using https://dbdocs.io/. Make sure you install DBDocs on your system by following these instructions: https://dbdocs.io/docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part a \n",
    "Write code using the [database markup language](https://dbml.dbdiagram.io/home/) (DBML) that represents all of the tables in this database and the connections between the tables. Paste your DBML code in a markdown cell in your notebook, contained within three backticks to begin and end the code snippet, as shown in the cell below. \n",
    "\n",
    "Two good resources to help you:\n",
    "\n",
    "1. The example on the Getting Started page on dbdocs.io: https://dbdocs.io/docs\n",
    "2. The full syntax guide for DBML: https://dbml.dbdiagram.io/docs/#project-definition\n",
    "\n",
    "A few notes:\n",
    "* Make sure to specify the data type for each column in each table. Use varchar for strings/text, int for integers, and float for numeric data with decimals.\n",
    "* You will probably find it useful to alias each table with one or two letters, such as: Table PRESCRIPTIONS as PR. That will allow you to use PR to refer to the PRESCRIPTIONS table, for example, in the Reference statements to link tables together.\n",
    "* Use the syntax [pk] after a column name and data type to designate the columns that are primary keys in each table.\n",
    "* To draw the lines linking one table to another, use the Ref: syntax.\n",
    "    * If many rows from the left table match to one row in the right table, use the \"many to one\" symbol >\n",
    "    * If one row from the left table matches to many rows in the right table, use the \"one to many\" symbol <\n",
    "    * If one row from the left table matches to one row in the right table, use the \"one to one\" symbol -\n",
    "    * If many rows from the left table match to many rows in the right table, use the \"many to many\" symbol <>\n",
    "      \n",
    "[2 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Make sure you get the .ipynb file for this lab from the module 6 page on Canvas\n",
    "\n",
    "Then when you double-click this box, you'll see three backticks before and after this text. Leave those alone\n",
    " \n",
    "Type your code here, between the backticks\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Project Lab6 {\n",
    "}\n",
    "\n",
    "Table PRESCRIPTIONS as PR {\n",
    "  patient_name varchar [pk]\n",
    "  date_of_birth varchar [pk]\n",
    "  prescribed_drug varchar [pk]\n",
    "}\n",
    "\n",
    "Table PATIENTS as PA {\n",
    "  patient_name varchar [pk]\n",
    "  date_of_birth varchar [pk]\n",
    "  patient_sex varchar\n",
    "  patient_insurance varchar\n",
    "  attending_physician varchar\n",
    "}\n",
    "\n",
    "Table DIAGNOSES as DI {\n",
    "  patient_name varchar [pk]\n",
    "  date_of_birth varchar [pk]\n",
    "  prior_condition varchar [pk]\n",
    "}\n",
    "\n",
    "Table DRUGS as DR {\n",
    "  prescribed_drug varchar [pk]\n",
    "  drug_maker varchar\n",
    "  drug_cost float\n",
    "}\n",
    "\n",
    "Table PHYSICIANS as PH {\n",
    "  attending_physician varchar [pk]\n",
    "  AP_medschool varchar \n",
    "  AP_years_experiece varchar\n",
    "  hospital varchar\n",
    "}\n",
    "\n",
    "Table HOSPITALS as H {\n",
    "  hospital varchar [pk]\n",
    "  hospital_location varchar\n",
    "}\n",
    "\n",
    "Ref: PR.patient_name > PA.patient_name\n",
    "Ref: PR.patient_name <> DI.patient_name\n",
    "Ref: PR.date_of_birth > PA.date_of_birth\n",
    "Ref: PR.date_of_birth <> DI.date_of_birth\n",
    "Ref: PR.prescribed_drug >  DR.prescribed_drug\n",
    "Ref: PA.attending_physician > PH.attending_physician\n",
    "Ref: PH.hospital > H.hospital\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part b\n",
    "Use the instructions on DBDocs.io (https://dbdocs.io/docs) to create a website for your ER diagram. Type the URL for your website in a markdown cell here. [2 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My example is here: https://dbdocs.io/jkropko/Lab6?view=relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3\n",
    "For this problem, you will download the individual CSV files that comprise a relational database on album reviews from [Pitchfork Magazine](https://pitchfork.com/), collected via webscraping by [Nolan B. Conaway](https://github.com/nolanbconaway/pitchfork-data), and use them to initialize local databases using SQlite, MySQL, and PostgreSQL. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code of code will download the CSV files. Please run this as is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% [....................................................] 83585024 / 83585024"
     ]
    }
   ],
   "source": [
    "url = \"https://github.com/nolanbconaway/pitchfork-data/raw/master/pitchfork.db\"\n",
    "pfork = wget.download(url)\n",
    "pitchfork = sqlite3.connect(pfork)\n",
    "for t in ['artists','content','genres','labels','reviews','years']:\n",
    "    datatable = pd.read_sql_query(\"SELECT * FROM {tab}\".format(tab=t), pitchfork)\n",
    "    datatable.to_csv(\"{tab}.csv\".format(tab=t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: this code downloaded a SQlite database and extracted the tables, saving each one as a CSV. That seems backwards, as the purpose of this exercise is to create databases. But the point here is to practice creating databases from individual data frames. Next we load the CSVs to create the data frames in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_csv(\"reviews.csv\")\n",
    "artists = pd.read_csv(\"artists.csv\")\n",
    "content = pd.read_csv(\"content.csv\")\n",
    "genres = pd.read_csv(\"genres.csv\")\n",
    "labels = pd.read_csv(\"labels.csv\")\n",
    "years = pd.read_csv(\"years.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part a\n",
    "Initialize a new database using SQlite and the `sqlite3` library. Add the six dataframes to this database. Then issue the following query to the database\n",
    "```\n",
    "SELECT title, artist, score FROM reviews WHERE score=10\n",
    "```\n",
    "using two methods: first, using the `.cursor()` method, and second using `pd.read_sql_query()`. Finally, commit your changes to the database and close the database. (If you get a warning about spaces in the column names, feel free to ignore it this time.) [2 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I initialize a new database using `sqlite3`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitchfork_db = sqlite3.connect(\"pitchfork.db\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I add the six dataframes to this database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19108"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.to_sql('reviews', pitchfork_db, index=False, if_exists='replace')\n",
    "artists.to_sql('artists', pitchfork_db, index=False, if_exists='replace')\n",
    "content.to_sql('content', pitchfork_db, index=False, if_exists='replace')\n",
    "genres.to_sql('genres', pitchfork_db, index=False, if_exists='replace')\n",
    "labels.to_sql('labels', pitchfork_db, index=False, if_exists='replace')\n",
    "years.to_sql('years', pitchfork_db, index=False, if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To query the database, I can use the cursor, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>artist</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>metal box</td>\n",
       "      <td>public image ltd</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blood on the tracks</td>\n",
       "      <td>bob dylan</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>another green world</td>\n",
       "      <td>brian eno</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>songs in the key of life</td>\n",
       "      <td>stevie wonder</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>in concert</td>\n",
       "      <td>nina simone</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>source tags and codes</td>\n",
       "      <td>...and you will know us by the trail of dead</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>the olatunji concert: the last live recording</td>\n",
       "      <td>john coltrane</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>kid a</td>\n",
       "      <td>radiohead</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>animals</td>\n",
       "      <td>pink floyd</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>i see a darkness</td>\n",
       "      <td>bonnie prince billy</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            title  \\\n",
       "0                                       metal box   \n",
       "1                             blood on the tracks   \n",
       "2                             another green world   \n",
       "3                        songs in the key of life   \n",
       "4                                      in concert   \n",
       "..                                            ...   \n",
       "71                          source tags and codes   \n",
       "72  the olatunji concert: the last live recording   \n",
       "73                                          kid a   \n",
       "74                                        animals   \n",
       "75                               i see a darkness   \n",
       "\n",
       "                                          artist  score  \n",
       "0                               public image ltd   10.0  \n",
       "1                                      bob dylan   10.0  \n",
       "2                                      brian eno   10.0  \n",
       "3                                  stevie wonder   10.0  \n",
       "4                                    nina simone   10.0  \n",
       "..                                           ...    ...  \n",
       "71  ...and you will know us by the trail of dead   10.0  \n",
       "72                                 john coltrane   10.0  \n",
       "73                                     radiohead   10.0  \n",
       "74                                    pink floyd   10.0  \n",
       "75                           bonnie prince billy   10.0  \n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pitchfork_cursor = pitchfork_db.cursor()\n",
    "pitchfork_cursor.execute(\"SELECT title, artist, score FROM reviews WHERE score=10\")\n",
    "colnames = [x[0] for x in pitchfork_cursor.description]\n",
    "pitchfork_df = pitchfork_cursor.fetchall()\n",
    "pd.DataFrame(pitchfork_df, columns=colnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also query the database using the `pd.read_sql_query()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>artist</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>metal box</td>\n",
       "      <td>public image ltd</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blood on the tracks</td>\n",
       "      <td>bob dylan</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>another green world</td>\n",
       "      <td>brian eno</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>songs in the key of life</td>\n",
       "      <td>stevie wonder</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>in concert</td>\n",
       "      <td>nina simone</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>source tags and codes</td>\n",
       "      <td>...and you will know us by the trail of dead</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>the olatunji concert: the last live recording</td>\n",
       "      <td>john coltrane</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>kid a</td>\n",
       "      <td>radiohead</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>animals</td>\n",
       "      <td>pink floyd</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>i see a darkness</td>\n",
       "      <td>bonnie prince billy</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            title  \\\n",
       "0                                       metal box   \n",
       "1                             blood on the tracks   \n",
       "2                             another green world   \n",
       "3                        songs in the key of life   \n",
       "4                                      in concert   \n",
       "..                                            ...   \n",
       "71                          source tags and codes   \n",
       "72  the olatunji concert: the last live recording   \n",
       "73                                          kid a   \n",
       "74                                        animals   \n",
       "75                               i see a darkness   \n",
       "\n",
       "                                          artist  score  \n",
       "0                               public image ltd   10.0  \n",
       "1                                      bob dylan   10.0  \n",
       "2                                      brian eno   10.0  \n",
       "3                                  stevie wonder   10.0  \n",
       "4                                    nina simone   10.0  \n",
       "..                                           ...    ...  \n",
       "71  ...and you will know us by the trail of dead   10.0  \n",
       "72                                 john coltrane   10.0  \n",
       "73                                     radiohead   10.0  \n",
       "74                                    pink floyd   10.0  \n",
       "75                           bonnie prince billy   10.0  \n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_sql_query(\"SELECT title, artist, score FROM reviews WHERE score=10\", pitchfork_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, I commit the changes and close the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitchfork_db.commit()\n",
    "pitchfork_db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part b\n",
    "Follow the instructions in the Jupyter notebook for this module to install MySQL and `mysql.connector` on your computer. Make sure the MySQL server is running. Then import `mysql.connector` and do all of the tasks listed for part a using a MySQL database (including commiting changes and closing the database connection). Take steps to hide your password - do not let it display in your notebook. [2 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I installed MySQL and `mysql.connector`, and I made sure the local MySQL server was running. I can now import the `mysql.connector` module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To hide my password, I write and save it in a `.env` file and load it here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mysqlpassword = os.getenv(\"mysqlpassword\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I connect to the MySQL server:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "InterfaceError",
     "evalue": "2003: Can't connect to MySQL server on 'localhost:3306' (61 Connection refused)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/site-packages/mysql/connector/network.py:758\u001b[0m, in \u001b[0;36mMySQLTCPSocket.open_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    757\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock\u001b[38;5;241m.\u001b[39msettimeout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection_timeout)\n\u001b[0;32m--> 758\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msockaddr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    759\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 61] Connection refused",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mInterfaceError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dbserver \u001b[38;5;241m=\u001b[39m \u001b[43mmysql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43muser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mroot\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpasswd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmysqlpassword\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlocalhost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      5\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/site-packages/mysql/connector/pooling.py:323\u001b[0m, in \u001b[0;36mconnect\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m CMySQLConnection \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m use_pure:\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m CMySQLConnection(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 323\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mMySQLConnection\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/site-packages/mysql/connector/connection.py:173\u001b[0m, in \u001b[0;36mMySQLConnection.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    175\u001b[0m         \u001b[38;5;66;03m# Tidy-up underlying socket on failure\u001b[39;00m\n\u001b[1;32m    176\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/site-packages/mysql/connector/abstracts.py:1363\u001b[0m, in \u001b[0;36mMySQLConnectionAbstract.connect\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1360\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1362\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisconnect()\n\u001b[0;32m-> 1363\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1365\u001b[0m charset, collation \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1366\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcharset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1367\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcollation\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1368\u001b[0m )\n\u001b[1;32m   1369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m charset \u001b[38;5;129;01mor\u001b[39;00m collation:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/site-packages/mysql/connector/connection.py:353\u001b[0m, in \u001b[0;36mMySQLConnection._open_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_socket \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_connection()\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 353\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_socket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;66;03m# do initial handshake\u001b[39;00m\n\u001b[1;32m    356\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_handshake()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/site-packages/mysql/connector/network.py:760\u001b[0m, in \u001b[0;36mMySQLTCPSocket.open_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock\u001b[38;5;241m.\u001b[39mconnect(sockaddr)\n\u001b[1;32m    759\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 760\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InterfaceError(\n\u001b[1;32m    761\u001b[0m         errno\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2003\u001b[39m,\n\u001b[1;32m    762\u001b[0m         values\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    763\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mserver_host,\n\u001b[1;32m    764\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mserver_port,\n\u001b[1;32m    765\u001b[0m             _strioerror(err),\n\u001b[1;32m    766\u001b[0m         ),\n\u001b[1;32m    767\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OperationalError(\u001b[38;5;28mstr\u001b[39m(err)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "\u001b[0;31mInterfaceError\u001b[0m: 2003: Can't connect to MySQL server on 'localhost:3306' (61 Connection refused)"
     ]
    }
   ],
   "source": [
    "dbserver = mysql.connector.connect(\n",
    "    user='root', \n",
    "    passwd=mysqlpassword, \n",
    "    host=\"localhost\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I create a new database on this server (deleting any existing version of this database first):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = dbserver.cursor()\n",
    "try:\n",
    "    cursor.execute(\"CREATE DATABASE pitchfork\")\n",
    "except:\n",
    "    cursor.execute(\"DROP DATABASE pitchfork\")\n",
    "    cursor.execute(\"CREATE DATABASE pitchfork\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To import the six dataframes into this database as entities, I create an engine with `sqlalchemy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = sqlalchemy.create_engine(\"mysql+mysqlconnector://{user}:{pw}@localhost/{db}?charset=utf8&use_pure\"\n",
    "                       .format(user=\"root\", pw=mysqlpassword, db=\"pitchfork\"), encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can now import data into the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.to_sql('reviews', con=engine, index=False, chunksize = 1000, if_exists='replace')\n",
    "artists.to_sql('artists', con=engine, index=False, chunksize = 1000, if_exists='replace')\n",
    "content.to_sql('content', con=engine, index=False, chunksize = 1000, if_exists='replace')\n",
    "genres.to_sql('genres', con=engine, index=False, chunksize = 1000, if_exists='replace')\n",
    "labels.to_sql('labels', con=engine, index=False, chunksize = 1000, if_exists='replace')\n",
    "years.to_sql('years', con=engine, index=False, chunksize = 1000, if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To issue a query using the cursor, I first open a direct connection to the `pitchfork` database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitchfork = mysql.connector.connect(\n",
    "    user='root', \n",
    "    password=mysqlpassword, \n",
    "    host=\"localhost\",\n",
    "    database=\"pitchfork\"\n",
    ")\n",
    "cursor = pitchfork.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I use the cursor to issue the query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"SELECT title, artist, score FROM reviews WHERE score=10\")\n",
    "colnames = [x[0] for x in cursor.description]\n",
    "pitchfork_df = cursor.fetchall()\n",
    "pd.DataFrame(pitchfork_df, columns=colnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, I can use the `sqlalchemy` engine with the `pd.read_sql_query()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql_query(\"SELECT title, artist, score FROM reviews WHERE score=10\", pitchfork)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally I commit the changes to the database and close the connection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbserver.commit()\n",
    "dbserver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part c\n",
    "Follow the instructions in the Jupyter notebook for this module to install PostgreSQL and `psycopg2` on your computer. Then import `psycopg2` and do all of the tasks listed for part a using a PostgreSQL database (including commiting changes and closing the database connection). Take steps to hide your password - do not let it display in your notebook. [2 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I installed PostgreSQL and `psycopg2`. I can now import the `psycopg2` library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To hide my password, I write and save it in a `.env` file and load it here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pgpassword = os.getenv(\"pgpassword\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I connect to the PostgreSQL server and turn on the autocommit behavior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbserver = psycopg2.connect(\n",
    "    user='jk8sd', \n",
    "    password=pgpassword, \n",
    "    host=\"localhost\"\n",
    ")\n",
    "dbserver.autocommit = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I create a new database on this server (deleting any existing version of this database first):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = dbserver.cursor()\n",
    "try:\n",
    "    cursor.execute(\"CREATE DATABASE pitchfork\")\n",
    "except:\n",
    "    cursor.execute(\"DROP DATABASE pitchfork\")\n",
    "    cursor.execute(\"CREATE DATABASE pitchfork\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To import the six dataframes into this database as entities, I create an engine with `sqlalchemy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = sqlalchemy.create_engine(\"postgresql+psycopg2://{user}:{pw}@localhost/{db}\"\n",
    "                       .format(user=\"jk8sd\", pw=pgpassword, db=\"pitchfork\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can now import data into the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.to_sql('reviews', con=engine, index=False, chunksize = 1000, if_exists='replace')\n",
    "artists.to_sql('artists', con=engine, index=False, chunksize = 1000, if_exists='replace')\n",
    "content.to_sql('content', con=engine, index=False, chunksize = 1000, if_exists='replace')\n",
    "genres.to_sql('genres', con=engine, index=False, chunksize = 1000, if_exists='replace')\n",
    "labels.to_sql('labels', con=engine, index=False, chunksize = 1000, if_exists='replace')\n",
    "years.to_sql('years', con=engine, index=False, chunksize = 1000, if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To issue a query using the cursor, I first open a direct connection to the `pitchfork` database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitchfork = psycopg2.connect(\n",
    "    user='jk8sd', \n",
    "    password=pgpassword, \n",
    "    host=\"localhost\",\n",
    "    database=\"pitchfork\"\n",
    ")\n",
    "cursor = pitchfork.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I use the cursor to issue the query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"SELECT title, artist, score FROM reviews WHERE score=10\")\n",
    "colnames = [x[0] for x in cursor.description]\n",
    "pitchfork_df = cursor.fetchall()\n",
    "pd.DataFrame(pitchfork_df, columns=colnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, I can use the `sqlalchemy` engine with the `pd.read_sql_query()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql_query(\"SELECT title, artist, score FROM reviews WHERE score=10\", pitchfork)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally I commit the changes to the database and close the connection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbserver.commit()\n",
    "dbserver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4\n",
    "[Colin Mitchell](http://muffinlabs.com/) is a web-developer and artist who has a bunch of [cool projects](http://muffinlabs.com/projects.html) that play with what data can do on the internet. One of his projects is [Today in History](https://history.muffinlabs.com/), which provides an API to access all the Wikipedia pages for historical events that happened on this day in JSON format. The records in this JSON are stored in the `['data']['events']` path. Here's the first listing for today:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = requests.get(\"https://history.muffinlabs.com/date\")\n",
    "history_json = json.loads(history.text)\n",
    "events = history_json['data']['Events']\n",
    "events[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this problem, you will use MongoDB and the `pymongo` library to create a local document store NoSQL database containing these historical events.\n",
    "\n",
    "Follow the instructions in the Jupyter notebook for this module to install MongoDB and `pymongo` on your computer. Make sure the local MongoDB server is running. Then import `pymongo`, connect to the local MongoDB client, create a database named \"history\" and a collection within that database named \"today\". Insert all of the records in `events` into this collection. Then issue the following query to find all of the records whose text contain the word \"Virginia\":\n",
    "```\n",
    "query = {\n",
    "    \"text\":{\n",
    "        \"$regex\": 'Virginia'\n",
    "    }\n",
    "}\n",
    "```\n",
    "If there are no results that contain the word \"Virginia\", choose a different work like \"England\" or \"China\". Display the count of the number of documents that match this query, display the output of the query, and generate a JSON formatted variable containing the output. [2 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I installed MongoDB and the `pymongo` library. I load `pymongo`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I connect to the MongoDB server running on my computer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myclient = pymongo.MongoClient(\"mongodb://localhost/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I create a database named \"history\" and a collection named \"today\". Because I will be running this code several times as I work, debugging as I go along, it's useful for me to delete any existing \"today\" collections before creating a new \"today\" collection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = myclient[\"history\"]\n",
    "\n",
    "collist = history.list_collection_names()\n",
    "if \"today\" in collist:\n",
    "  history.today.drop()\n",
    "today = history[\"today\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I put all of the records in `events` into the `today` collection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today.insert_many(events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can now issue the query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {\n",
    "    \"text\":{\n",
    "        \"$regex\": 'England'\n",
    "    }\n",
    "}\n",
    "today.count_documents(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To display this record, I can either use a loop that prints each record:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = today.find(query)\n",
    "for x in results:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To work with the result in JSON format, I use the `loads` and `dumps` methods from the `bson.json_util` module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bson.json_util import loads, dumps\n",
    "results_text = dumps(today.find(query))\n",
    "results_json = loads(results_text)\n",
    "results_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content.to_csv('content.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
